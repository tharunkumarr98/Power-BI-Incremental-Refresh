{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf536908-9eb8-47e9-8cc7-0b292b1bc247",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "%pip install termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43bfb326-d37e-450e-8856-257040f0c6e6",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-10-20T06:10:41.1423322Z",
       "execution_start_time": "2025-10-20T06:10:40.2196816Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "9a90fedd-4049-4d17-b719-3df4eb165148",
       "queued_time": "2025-10-20T06:10:22.3251256Z",
       "session_id": "887eab43-33a1-4658-89f8-56c313514548",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 21,
       "statement_ids": [
        21
       ]
      },
      "text/plain": [
       "StatementMeta(, 887eab43-33a1-4658-89f8-56c313514548, 21, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sempy import fabric\n",
    "from termcolor import cprint\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dee8d74-b71a-4b3a-8c8a-99efe6a194af",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Enter required details in the below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d885525e-78c2-4696-8808-05b6bf35dd0f",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-10-20T06:10:46.4200534Z",
       "execution_start_time": "2025-10-20T06:10:46.1040179Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "ada9a57a-2a11-48e2-a0ac-7aa7df1e790d",
       "queued_time": "2025-10-20T06:10:46.1029531Z",
       "session_id": "887eab43-33a1-4658-89f8-56c313514548",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 22,
       "statement_ids": [
        22
       ]
      },
      "text/plain": [
       "StatementMeta(, 887eab43-33a1-4658-89f8-56c313514548, 22, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasetId = \"\" #DatasetID\n",
    "workspaceId = \"\" #WorkspaceID\n",
    "tableName = \"\" #Table Name\n",
    "batchSize = 4 #number of partitions to refresh in a single batch\n",
    "delay = 180 #delay between each batch refresh in seconds\n",
    "payload = {\n",
    "    \"type\": \"Full\",\n",
    "    \"commitMode\": \"transactional\",\n",
    "    \"maxParallelism\": 2,\n",
    "    \"retryCount\": 1,\n",
    "    \"timeout\": \"02:00:00\",\n",
    "    \"objects\": [],\n",
    "    \"applyRefreshPolicy\": False\n",
    "}\n",
    "fullEndPoint = f\"https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/datasets/{datasetId}/refreshes\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e0ea302-132d-4001-a81a-64c6fa5fc290",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-10-20T06:10:51.259587Z",
       "execution_start_time": "2025-10-20T06:10:46.4222691Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "8d3ec28c-f797-4034-a87c-ab82e908d063",
       "queued_time": "2025-10-20T06:10:46.1583495Z",
       "session_id": "887eab43-33a1-4658-89f8-56c313514548",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 23,
       "statement_ids": [
        23
       ]
      },
      "text/plain": [
       "StatementMeta(, 887eab43-33a1-4658-89f8-56c313514548, 23, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_partitions = fabric.list_partitions(dataset=datasetId, workspace=workspaceId ,table=tableName)\n",
    "paritions = df_partitions[\"Partition Name\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f66a59d-e831-448c-8fd3-465b6d1ceb0a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-10-20T06:10:51.5673842Z",
       "execution_start_time": "2025-10-20T06:10:51.2620991Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "ed2b12dd-8717-4008-a315-bb24916a9b5e",
       "queued_time": "2025-10-20T06:10:46.2014513Z",
       "session_id": "887eab43-33a1-4658-89f8-56c313514548",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 24,
       "statement_ids": [
        24
       ]
      },
      "text/plain": [
       "StatementMeta(, 887eab43-33a1-4658-89f8-56c313514548, 24, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def refresh_partitions_in_batches(datasetId:str, workspaceId:str,tableName:str ,partitions:list):\n",
    "    batchCount = math.ceil(len(partitions) / batchSize) if len(partitions) > 0 else 0\n",
    "    client = fabric.FabricRestClient()\n",
    "    batch_num = 0\n",
    "\n",
    "    def getrefreshStatus():\n",
    "        response = client.get(f\"{fullEndPoint}?$top=1\")\n",
    "        return response.json().get(\"value\",{})[0].get(\"status\",\"\")\n",
    "\n",
    "    def postRefresh(payload):\n",
    "        response = client.post(fullEndPoint,json=payload)\n",
    "        return response.status_code\n",
    "    \n",
    "    # wait until service is idle before triggering this batch\n",
    "    while True and batch_num == 0:\n",
    "        status = getrefreshStatus()\n",
    "        cur_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        cprint(f\"Before triggering the first batch at {cur_time} last refresh status: {status}\",'blue')\n",
    "        if status in [\"Completed\", \"Failed\", \"None\"]:\n",
    "            cprint(\"ğŸ All to set to start\",'green')\n",
    "            break\n",
    "        cprint(\"â±ï¸ Waiting for {delay} seconds before checking status...\",'yellow')\n",
    "        time.sleep(delay)\n",
    "\n",
    "    cprint(f\"ğŸ“‹ Total Batches to process: {batchCount}\",'blue')\n",
    "\n",
    "    for batch_num in range(batchCount):\n",
    "        objects = []\n",
    "        temp = partitions[batch_num * batchSize : (batch_num + 1) * batchSize]\n",
    "        for i in temp:\n",
    "            objects.append({\"table\":tableName, \"partition\": i})\n",
    "        payload[\"objects\"] = objects\n",
    " \n",
    "        try:\n",
    "            # trigger the refresh for this batch\n",
    "            cprint(f\"ğŸ¹ Triggering for batch {batch_num + 1} with partitions: {temp}\",'yellow')\n",
    "            resp = postRefresh(payload=payload)\n",
    "            if resp != 202:\n",
    "                cprint(f\"ğŸ”´ Failed to trigger batch {batch_num + 1 }, response: {resp}\",'red')\n",
    "                # decide whether to retry or continue to next batch\n",
    "                continue\n",
    "            else:\n",
    "                cprint(f\"ğŸ¯ Batch {batch_num + 1} triggered successfully.\",'blue')\n",
    "\n",
    "            # poll until this triggered refresh finishes\n",
    "            while True:\n",
    "                cprint(f\"â±ï¸ Waiting for {delay} seconds before checking status...\",'yellow')\n",
    "                time.sleep(delay)\n",
    "                status = getrefreshStatus()\n",
    "                cur_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                cprint(f\"ğŸŸ¢ Current status {cur_time}: {status}\",'yellow')\n",
    "                if status in [\"Completed\", \"Failed\", \"None\"]:\n",
    "                    cprint(f\"ğŸï¸ Batch {batch_num + 1} finished with status: {status}\",'green' if status==\"Completed\" else 'red')\n",
    "                    if batch_num + 1 == batchCount:\n",
    "                        cprint(f\"âœ… All batches processed.\",'blue')\n",
    "                    break\n",
    "\n",
    "        except Exception as e:\n",
    "            cprint(f\"ğŸ”´ Error while running the API: {e}\",'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f955ab7-6904-4062-aaf5-663d84f7e429",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "refresh_partitions_in_batches(datasetId=datasetId,workspaceId=workspaceId,tableName=tableName,partitions=paritions)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {},
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "synapse_pyspark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
